{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9778892,"sourceType":"datasetVersion","datasetId":5990648},{"sourceId":9918667,"sourceType":"datasetVersion","datasetId":6095607},{"sourceId":9923859,"sourceType":"datasetVersion","datasetId":6099369}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install qwen_vl_utils","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:35:03.413539Z","iopub.execute_input":"2024-11-16T12:35:03.413831Z","iopub.status.idle":"2024-11-16T12:35:18.801611Z","shell.execute_reply.started":"2024-11-16T12:35:03.413794Z","shell.execute_reply":"2024-11-16T12:35:18.800357Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting qwen_vl_utils\n  Downloading qwen_vl_utils-0.0.8-py3-none-any.whl.metadata (3.6 kB)\nCollecting av (from qwen_vl_utils)\n  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from qwen_vl_utils) (21.3)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from qwen_vl_utils) (10.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from qwen_vl_utils) (2.32.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->qwen_vl_utils) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->qwen_vl_utils) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->qwen_vl_utils) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->qwen_vl_utils) (2024.8.30)\nDownloading qwen_vl_utils-0.0.8-py3-none-any.whl (5.9 kB)\nDownloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av, qwen_vl_utils\nSuccessfully installed av-13.1.0 qwen_vl_utils-0.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoProcessor, AutoModelForVision2Seq\n\nmodel_id = '/kaggle/input/new-cat1-mod/LLaMA-Factory/qwen2vl_2b_instruct_lora_merged_cat1_new'\n\n\nmodel = AutoModelForVision2Seq.from_pretrained(\n  model_id,\n  device_map=\"auto\",\n  torch_dtype=torch.float16,\n  # attn_implementation=\"flash_attention_2\",\n)\nprocessor = AutoProcessor.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:35:18.803910Z","iopub.execute_input":"2024-11-16T12:35:18.804312Z","iopub.status.idle":"2024-11-16T12:36:15.931341Z","shell.execute_reply.started":"2024-11-16T12:35:18.804266Z","shell.execute_reply":"2024-11-16T12:36:15.930260Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842e324aac064708a7f6a1cb05ca59d3"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n\ntest_df = pd.read_csv('/kaggle/input/mesho-chll/MESHO/test.csv')\n\n\nMen_Tshirts_df = test_df[test_df['Category'] == 'Men Tshirts']\n\n\nMen_Tshirts_df['image'] = Men_Tshirts_df['id'].apply(\n    lambda x: f\"/kaggle/input/mesho-chll/MESHO/test_images/{str(x).zfill(6)}.jpg\"\n)\n\n\nMen_Tshirts_df.to_csv('Men_Tshirts_df_cat1.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:36:15.932464Z","iopub.execute_input":"2024-11-16T12:36:15.933018Z","iopub.status.idle":"2024-11-16T12:36:16.047638Z","shell.execute_reply.started":"2024-11-16T12:36:15.932983Z","shell.execute_reply":"2024-11-16T12:36:16.046697Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1364480072.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  Women_Tshirts_df['image'] = Women_Tshirts_df['id'].apply(\n","output_type":"stream"}]},{"cell_type":"code","source":"men_df = pd.read_csv('/kaggle/working/Men_Tshirts_df_cat1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:36:16.049722Z","iopub.execute_input":"2024-11-16T12:36:16.050548Z","iopub.status.idle":"2024-11-16T12:36:16.061615Z","shell.execute_reply.started":"2024-11-16T12:36:16.050499Z","shell.execute_reply":"2024-11-16T12:36:16.060704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"men_df","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:36:26.721491Z","iopub.execute_input":"2024-11-16T12:36:26.722230Z","iopub.status.idle":"2024-11-16T12:36:26.740251Z","shell.execute_reply.started":"2024-11-16T12:36:26.722189Z","shell.execute_reply":"2024-11-16T12:36:26.739330Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        id     Category                                              image\n0        0  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/000...\n1        1  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/000...\n2        2  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/000...\n3        3  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/000...\n4        4  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/000...\n...    ...          ...                                                ...\n3782  3782  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/003...\n3783  3783  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/003...\n3784  3784  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/003...\n3785  3785  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/003...\n3786  3786  Men Tshirts  /kaggle/input/mesho-chll/MESHO/test_images/003...\n\n[3787 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/000...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/000...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/000...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3782</th>\n      <td>3782</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/003...</td>\n    </tr>\n    <tr>\n      <th>3783</th>\n      <td>3783</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/003...</td>\n    </tr>\n    <tr>\n      <th>3784</th>\n      <td>3784</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/003...</td>\n    </tr>\n    <tr>\n      <th>3785</th>\n      <td>3785</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/003...</td>\n    </tr>\n    <tr>\n      <th>3786</th>\n      <td>3786</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/mesho-chll/MESHO/test_images/003...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3787 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from qwen_vl_utils import process_vision_info\ndef generate_description(sample, model, processor):\n    prompt = \"\"\"Given the provided product category (##CATEGORY##) and its corresponding image, please predict the following attributes for the product: attr_1 to attr_10 based on previously observed patterns and examples. Ensure that your predictions are accurate and relevant to the visual characteristics in the image.\n\n    ##CATEGORY##: {category}\n    \"\"\"\n    \n            \n         \n    messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": prompt.format(category=sample[\"Category\"]),\n                    },\n                    {\n                        \"type\": \"image\",\n                        \"image\": sample[\"image\"],\n                    }\n                ],\n            },\n           \n        ]\n   \n    text = processor.apply_chat_template(\n        messages, tokenize=False, add_generation_prompt=True\n    )\n    image_inputs, video_inputs = process_vision_info(messages)\n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n    )\n    inputs = inputs.to(model.device)\n\n    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8)\n    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n    output_text = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )\n    return output_text[0]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:36:42.738495Z","iopub.execute_input":"2024-11-16T12:36:42.738869Z","iopub.status.idle":"2024-11-16T12:36:42.748712Z","shell.execute_reply.started":"2024-11-16T12:36:42.738832Z","shell.execute_reply":"2024-11-16T12:36:42.747533Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd\n\n\nresults = []\n\n\nfor index, row in tqdm(men_df.iterrows(), total=men_df.shape[0]):\n    try:\n       \n        description_text = generate_description(row, model, processor)\n        \n        \n        description_dict = eval(description_text)  \n        result = {\n            \"id\": row[\"id\"],\n            \"Category\": row[\"Category\"]\n        }\n        \n       \n        attr_count = 0  \n        for i in range(1, 11):\n            attr_key = f\"attr_{i}\"\n            attr_value = description_dict.get(attr_key, \"\")\n            result[attr_key] = attr_value\n            if attr_value.lower() != \"no\":\n                attr_count += 1  \n        \n        \n        result[\"len\"] = attr_count\n        results.append(result)\n    \n    except Exception as e:\n        print(f\"Error processing id {row['id']}: {e}\")\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv('cat1_new.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T12:36:45.804521Z","iopub.execute_input":"2024-11-16T12:36:45.804897Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  1%|          | 29/3787 [02:29<5:12:36,  4.99s/it]","output_type":"stream"}]}]}